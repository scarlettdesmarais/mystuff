{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-12 17:47:04.201082\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "\n",
    "import datetime\n",
    "print(datetime.datetime.now())\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class clean_text:\n",
    "        \n",
    "    def split_text(self, t):\n",
    "        return t.apply(lambda x: str(x).split(\" \"))\n",
    "    \n",
    "    def to_lower(self, t):\n",
    "        return t.apply(lambda x:   str(x).lower())\n",
    "    \n",
    "    \n",
    "    def remove_mentions(self,t):\n",
    "        return t.apply(lambda x:  re.sub(r'@\\w+', '', str(x)))\n",
    "    \n",
    "    def remove_numbers(self, t):\n",
    "        return t.apply(lambda x: re.sub(r'\\d+', '', str(x)))\n",
    "    \n",
    "\n",
    "    def remove_urls(self, t):\n",
    "        return t.apply(lambda x: re.sub(r'http.?://[^\\s]+[\\s]?', '', str(x)))\n",
    "    \n",
    "    def remove_punctuation(self,t):\n",
    "         return t.apply(lambda x: str(x).translate(str.maketrans('','',string.punctuation)))\n",
    "        \n",
    "\n",
    "    def remove_stopwords(self, t):\n",
    "        return t.apply(lambda x: [word for word in str(x).split(\" \") if word not in stopwords.words('english')])\n",
    "    \n",
    "    def stemming(self,t):\n",
    "        temp= t.apply(lambda x: str(x).split(\" \"))\n",
    "        porter = PorterStemmer()\n",
    "        stemmed = temp.apply(lambda x: porter.stem(\" \".join(x)))\n",
    "        return stemmed\n",
    "    \n",
    "    def ready_data(self, t):\n",
    "        t1 = self.remove_mentions(t)\n",
    "        t2 = self.remove_urls(t1)\n",
    "        t3 = self.remove_punctuation(t2)\n",
    "        t4 = self.to_lower(t3)\n",
    "        t5 = self.remove_numbers(t4)\n",
    "        t6 = self.stemming(t5)\n",
    "        \n",
    "        return t6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv('Downloads/sentiment_train.csv')\n",
    "b = pd.read_csv('Downloads/sentiment_test.csv')\n",
    "X_train = a['Sentence']\n",
    "y_train = a['Polarity']\n",
    "X_test = b['Sentence']\n",
    "y_test = b['Polarity']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline to extract features using TF-IDF Vectorizer and compare classifiers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation result for Logistic Regression\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "accuracy score: 75.17%\n",
      "train and test time: 0.32s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for Linear SVC\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "          verbose=0)\n",
      "accuracy score: 78.17%\n",
      "train and test time: 0.16s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for LinearSVC with L1-based feature selection\n",
      "Pipeline(memory=None,\n",
      "         steps=[('feature_selection',\n",
      "                 SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None,\n",
      "                                                     dual=False,\n",
      "                                                     fit_intercept=True,\n",
      "                                                     intercept_scaling=1,\n",
      "                                                     loss='squared_hinge',\n",
      "                                                     max_iter=1000,\n",
      "                                                     multi_class='ovr',\n",
      "                                                     penalty='l1',\n",
      "                                                     random_state=None,\n",
      "                                                     tol=0.0001, verbose=0),\n",
      "                                 max_features=None, norm_order=1, prefit=False,\n",
      "                                 threshold=None)),\n",
      "                ('classification',\n",
      "                 LinearSVC(C=1.0, class_weight=None, dual=True,\n",
      "                           fit_intercept=True, intercept_scaling=1,\n",
      "                           loss='squared_hinge', max_iter=1000,\n",
      "                           multi_class='ovr', penalty='l2', random_state=None,\n",
      "                           tol=0.0001, verbose=0))],\n",
      "         verbose=False)\n",
      "accuracy score: 75.67%\n",
      "train and test time: 0.15s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for Multinomial NB\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "accuracy score: 76.00%\n",
      "train and test time: 0.12s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for Bernoulli NB\n",
      "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "accuracy score: 75.50%\n",
      "train and test time: 0.12s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for Ridge Classifier\n",
      "RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "                max_iter=None, normalize=False, random_state=None,\n",
      "                solver='auto', tol=0.001)\n",
      "accuracy score: 77.33%\n",
      "train and test time: 0.14s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for AdaBoost\n",
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
      "                   n_estimators=50, random_state=None)\n",
      "accuracy score: 65.50%\n",
      "train and test time: 0.53s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for Perceptron\n",
      "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
      "           fit_intercept=True, max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
      "           penalty=None, random_state=0, shuffle=True, tol=0.001,\n",
      "           validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "accuracy score: 77.33%\n",
      "train and test time: 0.12s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for Passive-Aggresive\n",
      "PassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,\n",
      "                            early_stopping=False, fit_intercept=True,\n",
      "                            loss='hinge', max_iter=1000, n_iter_no_change=5,\n",
      "                            n_jobs=None, random_state=None, shuffle=True,\n",
      "                            tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "                            warm_start=False)\n",
      "accuracy score: 77.17%\n",
      "train and test time: 0.12s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for Nearest Centroid\n",
      "NearestCentroid(metric='euclidean', shrink_threshold=None)\n",
      "accuracy score: 70.17%\n",
      "train and test time: 0.11s\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score \n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "\n",
    "def acc_summary(pipeline, x_train, y_train, x_test, y_test):\n",
    "    t0 = time()\n",
    "    sentiment_fit = pipeline.fit(x_train, y_train)\n",
    "    y_pred = sentiment_fit.predict(x_test)\n",
    "    train_test_time = time() - t0\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"accuracy score: {0:.2f}%\".format(accuracy*100))\n",
    "    print (\"train and test time: {0:.2f}s\".format(train_test_time))\n",
    "    print (\"-\"*80)\n",
    "    return accuracy, train_test_time\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tvec = TfidfVectorizer()\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "names = [\"Logistic Regression\", \"Linear SVC\", \"LinearSVC with L1-based feature selection\",\"Multinomial NB\", \n",
    "         \"Bernoulli NB\", \"Ridge Classifier\", \"AdaBoost\", \"Perceptron\",\"Passive-Aggresive\", \"Nearest Centroid\"]\n",
    "classifiers = [\n",
    "    LogisticRegression(),\n",
    "    LinearSVC(),\n",
    "    Pipeline([\n",
    "  ('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\", dual=False))),\n",
    "  ('classification', LinearSVC(penalty=\"l2\"))]),\n",
    "    MultinomialNB(),\n",
    "    BernoulliNB(),\n",
    "    RidgeClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    Perceptron(),\n",
    "    PassiveAggressiveClassifier(),\n",
    "    NearestCentroid()\n",
    "    ]\n",
    "zipped_clf = zip(names,classifiers)\n",
    "\n",
    "tvec = TfidfVectorizer()\n",
    "def classifier_comparator(vectorizer=tvec, n_features=10000, stop_words=None, ngram_range=(1, 1), classifier=zipped_clf):\n",
    "    result = []\n",
    "    vectorizer.set_params(stop_words=stop_words, max_features=n_features, ngram_range=ngram_range)\n",
    "    for n,c in classifier:\n",
    "        checker_pipeline = Pipeline([\n",
    "            ('vectorizer', vectorizer),\n",
    "            ('classifier', c)\n",
    "        ])\n",
    "        print (\"Validation result for {}\".format(n))\n",
    "        print (c)\n",
    "        clf_acc,tt_time = acc_summary(checker_pipeline, X_train, y_train, X_test, y_test)\n",
    "        result.append((n,clf_acc,tt_time))\n",
    "    return result\n",
    "\n",
    "trigram_result = classifier_comparator(n_features=100000,ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline to predict using with LinearSVC since it had the best accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation result for Linear SVC\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "          verbose=0)\n",
      "accuracy score: 78.17%\n",
      "train and test time: 0.13s\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score \n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "\n",
    "def acc_summary(pipeline, x_train, y_train, x_test, y_test):\n",
    "    t0 = time()\n",
    "    sentiment_fit = pipeline.fit(x_train, y_train)\n",
    "    y_pred = sentiment_fit.predict(x_test)\n",
    "    train_test_time = time() - t0\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"accuracy score: {0:.2f}%\".format(accuracy*100))\n",
    "    print (\"train and test time: {0:.2f}s\".format(train_test_time))\n",
    "    print (\"-\"*80)\n",
    "    return accuracy, train_test_time, y_pred\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tvec = TfidfVectorizer()\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "names = [ \"Linear SVC\"]\n",
    "classifiers = [\n",
    "    LinearSVC() ]\n",
    "zipped_clf = zip(names,classifiers)\n",
    "\n",
    "tvec = TfidfVectorizer()\n",
    "def classifier_comparator(vectorizer=tvec, n_features=10000, stop_words=None, ngram_range=(1, 1), classifier=zipped_clf):\n",
    "    result = []\n",
    "    vectorizer.set_params(stop_words=stop_words, max_features=n_features, ngram_range=ngram_range)\n",
    "    for n,c in classifier:\n",
    "        checker_pipeline = Pipeline([\n",
    "            ('vectorizer', vectorizer),\n",
    "            ('classifier', c)\n",
    "        ])\n",
    "        print (\"Validation result for {}\".format(n))\n",
    "        print (c)\n",
    "        clf_acc,tt_time,y_pred = acc_summary(checker_pipeline, X_train, y_train, X_test, y_test)\n",
    "        result.append((n,clf_acc,tt_time))\n",
    "    return result, y_pred\n",
    "\n",
    "trigram_result,y_pred = classifier_comparator(n_features=100000,ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>predicted</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A good commentary of today's love and undoubte...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>For people who are first timers in film making...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It was very popular when I was in the cinema, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It's a feel-good film and that's how I felt wh...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It has northern humour and positive about the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  Polarity  predicted  \\\n",
       "0  A good commentary of today's love and undoubte...         1          1   \n",
       "1  For people who are first timers in film making...         1          1   \n",
       "2  It was very popular when I was in the cinema, ...         1          1   \n",
       "3  It's a feel-good film and that's how I felt wh...         1          0   \n",
       "4  It has northern humour and positive about the ...         1          1   \n",
       "\n",
       "   Predicted  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          0  \n",
       "4          1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Setting the predicted values as a column in test dataset\n",
    "b['Predicted'] = y_pred\n",
    "b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
